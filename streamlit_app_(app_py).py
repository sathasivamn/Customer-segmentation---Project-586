# -*- coding: utf-8 -*-
"""Streamlit App (app.py).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UnSxNuyIH4Fhx6fo6C65l9aMxodS7M81
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install streamlit

# Define the functions from utils.py here
import joblib
import pandas as pd
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from pathlib import Path

def load_artifacts():
    """Loads the preprocessor, model, and sample data with clusters."""
    out_dir = Path("/content/cluster_outputs") # Assuming the artifacts are in this directory

    preprocessor_path = out_dir / "preprocessor.joblib"
    model_path = None
    # Find the model file (assuming it starts with best_model_)
    for f in out_dir.iterdir():
        if f.name.startswith("best_model_") and f.suffix == ".joblib":
            model_path = f
            break

    data_path = out_dir / "data_with_clusters.csv"

    if not preprocessor_path.exists():
        raise FileNotFoundError(f"Preprocessor artifact not found at {preprocessor_path}")
    if not model_path:
         raise FileNotFoundError(f"Model artifact not found in {out_dir}. Looked for files starting with 'best_model_'")
    if not data_path.exists():
        # This is not a critical error for the app to run prediction, but inform the user
        print(f"Warning: Sample data with clusters not found at {data_path}. Sample data display will be disabled.")
        sample_df = None
    else:
        sample_df = pd.read_csv(data_path)

    preprocessor = joblib.load(preprocessor_path)
    model = joblib.load(model_path)


    return preprocessor, model, sample_df


def predict_cluster_for_input(model, preprocessor, input_df):
    """Predicts the cluster for a given input DataFrame."""
    # Apply the same preprocessing as used for training
    input_processed = preprocessor.transform(input_df)

    # Predict the cluster label
    # Assuming the model has a predict method for clustering (like KMeans)
    # For some clustering algorithms (like AgglomerativeClustering), you might use fit_predict on the single row
    # If it's a classification model predicting clusters, then predict is appropriate.
    # Assuming predict_proba for soft clustering or predict for hard clustering.
    # Let's assume a predict method exists that returns a single label or a list of labels
    # If the model is a clustering model like KMeans, predict returns the cluster index
    # If the model is a classifier trained on cluster labels, it returns the predicted label
    # Assuming a simple case where predict returns a single label or index
    prediction = model.predict(input_processed)

    # Return the first prediction (assuming a single row input)
    return prediction[0]

